{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c5ab7a",
   "metadata": {},
   "source": [
    "# INTEGRANTES\n",
    "\n",
    "### Arrieta Palacios Andrés Leonardo - 20200153\n",
    "### Alfaro Mauricio Kevin Johan - 20200242\n",
    "### Taipe Javier Luis Angel - 20200118"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6c2f69",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f767e01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6000b7",
   "metadata": {},
   "source": [
    "### Lectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8ef38a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEMPERATURA\n",
    "# Lee el primer archivo CSV\n",
    "tmp1 = pd.read_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\Untitled-temperature.csv')\n",
    "\n",
    "# Lee el segundo archivo CSV\n",
    "tmp2 = pd.read_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\Untitled-temperature(1).csv')\n",
    "\n",
    "# Lee el tercer archivo CSV\n",
    "tmp3 = pd.read_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\Untitled-temperature(2).csv')\n",
    "\n",
    "# Lee el cuarto archivo CSV\n",
    "tmp4 = pd.read_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\Untitled-temperature(3).csv')\n",
    "\n",
    "# Lee el quinto archivo CSV\n",
    "tmp5 = pd.read_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\Untitled-temperature(4).csv')\n",
    "\n",
    "# Lee el sexto archivo CSV\n",
    "tmp6 = pd.read_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\Untitled-temperature(5).csv')\n",
    "\n",
    "# Lee el septimo archivo CSV\n",
    "tmp7 = pd.read_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\Untitled-temperature(6).csv')\n",
    "\n",
    "# Lee el octavo  archivo CSV\n",
    "tmp8 = pd.read_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\Untitled-temperature(7).csv')\n",
    "\n",
    "#HUMEDAD\n",
    "# Lee el primer archivo CSV\n",
    "hmd1 = pd.read_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\Untitled-humidity.csv')\n",
    "\n",
    "# Lee el segundo archivo CSV\n",
    "hmd2 = pd.read_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\Untitled-humidity(1).csv')\n",
    "\n",
    "# Lee el tercer archivo CSV\n",
    "hmd3 = pd.read_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\Untitled-humidity(2).csv')\n",
    "\n",
    "# Lee el cuarto archivo CSV\n",
    "hmd4 = pd.read_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\Untitled-humidity(3).csv')\n",
    "\n",
    "# Lee el quinto archivo CSV\n",
    "hmd5 = pd.read_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\Untitled-humidity(4).csv')\n",
    "\n",
    "# Lee el sexto archivo CSV\n",
    "hmd6 = pd.read_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\Untitled-humidity(5).csv')\n",
    "\n",
    "# Lee el septimo archivo CSV\n",
    "hmd7 = pd.read_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\Untitled-humidity(6).csv')\n",
    "\n",
    "# Lee el octavo archivo CSV\n",
    "hmd8 = pd.read_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\Untitled-humidity(7).csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c9a76",
   "metadata": {},
   "source": [
    "### Consistencia de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae049caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEMPERATURA\n",
    "# Convierte la columna 'time' en un objeto de fecha y hora\n",
    "tmp1['time'] = pd.to_datetime(tmp1['time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "# Redondea la columna 'value' a 2 decimales\n",
    "tmp1['value'] = tmp1['value'].round(2)\n",
    "\n",
    "# Convierte la columna 'time' en un objeto de fecha y hora\n",
    "tmp2['time'] = pd.to_datetime(tmp2['time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "# Redondea la columna 'value' a 2 decimales\n",
    "tmp2['value'] = tmp2['value'].round(2)\n",
    "\n",
    "# Convierte la columna 'time' en un objeto de fecha y hora\n",
    "tmp3['time'] = pd.to_datetime(tmp3['time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "# Redondea la columna 'value' a 2 decimales\n",
    "tmp3['value'] = tmp3['value'].round(2)\n",
    "\n",
    "# Convierte la columna 'time' en un objeto de fecha y hora\n",
    "tmp4['time'] = pd.to_datetime(tmp4['time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "# Redondea la columna 'value' a 2 decimales\n",
    "tmp4['value'] = tmp4['value'].round(2)\n",
    "\n",
    "# Convierte la columna 'time' en un objeto de fecha y hora\n",
    "tmp5['time'] = pd.to_datetime(tmp5['time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "# Redondea la columna 'value' a 2 decimales\n",
    "tmp5['value'] = tmp5['value'].round(2)\n",
    "\n",
    "# Convierte la columna 'time' en un objeto de fecha y hora\n",
    "tmp6['time'] = pd.to_datetime(tmp6['time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "# Redondea la columna 'value' a 2 decimales\n",
    "tmp6['value'] = tmp6['value'].round(2)\n",
    "\n",
    "# Convierte la columna 'time' en un objeto de fecha y hora\n",
    "tmp7['time'] = pd.to_datetime(tmp7['time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "# Redondea la columna 'value' a 2 decimales\n",
    "tmp7['value'] = tmp7['value'].round(2)\n",
    "\n",
    "# Convierte la columna 'time' en un objeto de fecha y hora\n",
    "tmp8['time'] = pd.to_datetime(tmp8['time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "# Redondea la columna 'value' a 2 decimales\n",
    "tmp8['value'] = tmp8['value'].round(2)\n",
    "\n",
    "\n",
    "#HUMEDAD\n",
    "# Convierte la columna 'time' en un objeto de fecha y hora\n",
    "hmd1['time'] = pd.to_datetime(hmd1['time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "# Convierte la columna 'time' en un objeto de fecha y hora\n",
    "hmd2['time'] = pd.to_datetime(hmd2['time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "# Convierte la columna 'time' en un objeto de fecha y hora\n",
    "hmd3['time'] = pd.to_datetime(hmd3['time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "# Convierte la columna 'time' en un objeto de fecha y hora\n",
    "hmd4['time'] = pd.to_datetime(hmd4['time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "# Convierte la columna 'time' en un objeto de fecha y hora\n",
    "hmd5['time'] = pd.to_datetime(hmd5['time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "# Convierte la columna 'time' en un objeto de fecha y hora\n",
    "hmd6['time'] = pd.to_datetime(hmd6['time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "# Convierte la columna 'time' en un objeto de fecha y hora\n",
    "hmd7['time'] = pd.to_datetime(hmd7['time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "# Convierte la columna 'time' en un objeto de fecha y hora\n",
    "hmd8['time'] = pd.to_datetime(hmd8['time'], format='%Y-%m-%dT%H:%M:%S.%fZ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c48c052",
   "metadata": {},
   "source": [
    "### Combinar en archivo resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "359d2a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEMPERATURA\n",
    "# Combina ambos DataFrames en uno solo\n",
    "df_combinedt = pd.concat([tmp1, tmp2], ignore_index=True)\n",
    "\n",
    "# Guarda los datos procesados y combinados en un nuevo archivo CSV\n",
    "df_combinedt.to_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\TEMPERATURA.csv', index=False)\n",
    "\n",
    "# Combina ambos DataFrames en uno solo\n",
    "df_combinedt2 = pd.concat([tmp3, tmp4], ignore_index=True)\n",
    "\n",
    "# Guarda los datos procesados y combinados en un nuevo archivo CSV\n",
    "df_combinedt2.to_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\TEMPERATURA2.csv', index=False)\n",
    "\n",
    "# Combina ambos DataFrames en uno solo\n",
    "tmp56 = pd.concat([tmp5, tmp6], ignore_index=True)\n",
    "\n",
    "df_combinedt3 = pd.concat([tmp56, tmp7], ignore_index=True)\n",
    "\n",
    "# Guarda los datos procesados y combinados en un nuevo archivo CSV\n",
    "df_combinedt3.to_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\TEMPERATURA3.csv', index=False)\n",
    "\n",
    "#HUMEDAD\n",
    "# Combina ambos DataFrames en uno solo\n",
    "df_combinedh = pd.concat([hmd1, hmd2], ignore_index=True)\n",
    "\n",
    "# Guarda los datos procesados y combinados en un nuevo archivo CSV\n",
    "df_combinedh.to_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\HUMEDAD.csv', index=False)\n",
    "\n",
    "# Combina ambos DataFrames en uno solo\n",
    "df_combinedh2 = pd.concat([hmd3, hmd4], ignore_index=True)\n",
    "\n",
    "# Guarda los datos procesados y combinados en un nuevo archivo CSV\n",
    "df_combinedh2.to_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\HUMEDAD2.csv', index=False)\n",
    "\n",
    "# Combina ambos DataFrames en uno solo\n",
    "hmd56 = pd.concat([hmd5, hmd6], ignore_index=True)\n",
    "\n",
    "df_combinedh3 = pd.concat([hmd56, hmd7], ignore_index=True)\n",
    "\n",
    "# Guarda los datos procesados y combinados en un nuevo archivo CSV\n",
    "df_combinedh3.to_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\HUMEDAD3.csv', index=False)\n",
    " \n",
    "##COMBINACION DEFINITIVA\n",
    "\n",
    "combinat24 = pd.concat([tmp2, tmp4], ignore_index=True)\n",
    "\n",
    "combinat247 = pd.concat([combinat24, tmp7], ignore_index=True)\n",
    "\n",
    "combinat = pd.concat([combinat247, tmp8], ignore_index=True)\n",
    "# Guarda los datos procesados y combinados en un nuevo archivo CSV\n",
    "combinat.to_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\TEMP.csv', index=False)\n",
    "\n",
    "\n",
    "combinah24 = pd.concat([hmd2, hmd4], ignore_index=True)\n",
    "\n",
    "combinah247 = pd.concat([combinah24, hmd7], ignore_index=True)\n",
    "\n",
    "combinah = pd.concat([combinah247, hmd8], ignore_index=True)\n",
    "# Guarda los datos procesados y combinados en un nuevo archivo CSV\n",
    "combinah.to_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\HUME.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0ce5d5",
   "metadata": {},
   "source": [
    "# FORMATO FINAL TEMPERATURA Y HUMEDAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0defa131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     fecha y hora  temperatura\n",
      "0   2023-11-07 04:40:58.495638584         22.6\n",
      "1   2023-11-07 04:41:37.044009356         22.5\n",
      "2   2023-11-07 04:45:22.162484770         25.2\n",
      "3   2023-11-07 04:45:27.180533095         25.3\n",
      "4   2023-11-07 04:45:33.160075050         25.4\n",
      "..                            ...          ...\n",
      "986 2023-11-10 11:26:43.881348469         21.6\n",
      "987 2023-11-10 11:41:43.867513397         21.5\n",
      "988 2023-11-10 11:56:43.849197813         21.1\n",
      "989 2023-11-10 12:11:43.872917926         21.1\n",
      "990 2023-11-10 12:22:05.238805337         21.0\n",
      "\n",
      "[991 rows x 2 columns]\n",
      "                     fecha y hora  humedad\n",
      "0   2023-11-07 04:40:58.495638584       67\n",
      "1   2023-11-07 04:45:22.162484770       89\n",
      "2   2023-11-07 04:45:39.162345328       88\n",
      "3   2023-11-07 04:46:09.080341911       87\n",
      "4   2023-11-07 04:46:09.176283175       86\n",
      "..                            ...      ...\n",
      "940 2023-11-10 11:26:43.881348469       70\n",
      "941 2023-11-10 11:41:43.867513397       72\n",
      "942 2023-11-10 11:56:43.849197813       73\n",
      "943 2023-11-10 12:11:43.872917926       74\n",
      "944 2023-11-10 12:22:05.238805337       74\n",
      "\n",
      "[945 rows x 2 columns]\n",
      "                      fecha y hora  temperatura  humedad\n",
      "0    2023-11-07 04:40:58.495638584         22.6       67\n",
      "4    2023-11-07 04:45:22.162484770         25.2       89\n",
      "8    2023-11-07 04:46:09.176283175         25.6       86\n",
      "12   2023-11-07 04:46:09.266258334         25.7       85\n",
      "16   2023-11-07 04:46:09.460580286         26.2       87\n",
      "...                            ...          ...      ...\n",
      "1012 2023-11-10 11:26:43.881348469         21.6       70\n",
      "1013 2023-11-10 11:41:43.867513397         21.5       72\n",
      "1014 2023-11-10 11:56:43.849197813         21.1       73\n",
      "1015 2023-11-10 12:11:43.872917926         21.1       74\n",
      "1016 2023-11-10 12:22:05.238805337         21.0       74\n",
      "\n",
      "[274 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#PRIMEROS\n",
    "df_combinedt = df_combinedt.rename(columns={'time': 'fecha y hora', 'value': 'temperatura'})\n",
    "\n",
    "df_combinedh = df_combinedh.rename(columns={'time': 'fecha y hora','value': 'humedad'})\n",
    "\n",
    "# Combina ambos DataFrames utilizando la columna 'time' como clave\n",
    "df_final = pd.merge(df_combinedt, df_combinedh[['fecha y hora', 'humedad']], on='fecha y hora', how='left')\n",
    "df_final_nd = df_final.drop_duplicates()\n",
    "\n",
    "#SEGUNDOS\n",
    "df_combinedt2 = df_combinedt2.rename(columns={'time': 'fecha y hora', 'value': 'temperatura'})\n",
    "\n",
    "df_combinedh2 = df_combinedh2.rename(columns={'time': 'fecha y hora','value': 'humedad'})\n",
    "\n",
    "# Combina ambos DataFrames utilizando la columna 'time' como clave\n",
    "df_final2 = pd.merge(df_combinedt2, df_combinedh2[['fecha y hora', 'humedad']], on='fecha y hora', how='left')\n",
    "df_final_nd2 = df_final2.drop_duplicates()\n",
    "\n",
    "#TERCEROS\n",
    "df_combinedt3 = df_combinedt3.rename(columns={'time': 'fecha y hora', 'value': 'temperatura'})\n",
    "\n",
    "df_combinedh3 = df_combinedh3.rename(columns={'time': 'fecha y hora','value': 'humedad'})\n",
    "\n",
    "# Combina ambos DataFrames utilizando la columna 'time' como clave\n",
    "df_final3 = pd.merge(df_combinedt3, df_combinedh3[['fecha y hora', 'humedad']], on='fecha y hora', how='left')\n",
    "df_final_nd3 = df_final3.drop_duplicates()\n",
    "\n",
    "# Guarda el resultado en un archivo CSV final\n",
    "df_final_nd.to_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\DATA_TEMPERATURA_y_HUMEDAD.csv', index=False)\n",
    "# Guarda el resultado en un archivo CSV final\n",
    "df_final_nd2.to_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\DATA_TEMPERATURA_y_HUMEDAD2.csv', index=False)\n",
    "# Guarda el resultado en un archivo CSV final\n",
    "df_final_nd3.to_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\DATA_TEMPERATURA_y_HUMEDAD3.csv', index=False)\n",
    "\n",
    "# DEFINITIVO\n",
    "combinat = combinat.rename(columns={'time': 'fecha y hora', 'value': 'temperatura'})\n",
    "\n",
    "combinah = combinah.rename(columns={'time': 'fecha y hora','value': 'humedad'})\n",
    "\n",
    "# Combina ambos DataFrames utilizando la columna 'time' como clave\n",
    "tyh_df = pd.merge(combinat, combinah[['fecha y hora', 'humedad']], on='fecha y hora', how='inner')\n",
    "tyh_df_nd = tyh_df.drop_duplicates()\n",
    "\n",
    "tyh_df_nd.to_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\DATA_TEMP_y_HUME.csv', index=False)\n",
    "\n",
    "print(combinat)\n",
    "print(combinah)\n",
    "print(tyh_df_nd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908d6c3a",
   "metadata": {},
   "source": [
    "# ENTREGABLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbebfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "entregable = pd.concat([df_final_nd2, df_final_nd3], ignore_index=True)\n",
    "\n",
    "entregable.to_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\DATA_TEMPERATURA_y_HUMEDAD_G1.csv', index=False)\n",
    "\n",
    "# Número exacto de filas deseadas (300)\n",
    "num_filas_deseadas = 300\n",
    "\n",
    "# Calcula el número de filas a eliminar aleatoriamente (hasta 2)\n",
    "num_filas_eliminar = max(0, len(entregable) - num_filas_deseadas)\n",
    "\n",
    "# Elimina filas aleatorias si es necesario\n",
    "if num_filas_eliminar > 0:\n",
    "    filas_a_eliminar = random.sample(range(len(entregable)), num_filas_eliminar)\n",
    "    entregable = entregable.drop(filas_a_eliminar)\n",
    "\n",
    "# Guarda el resultado en un nuevo archivo CSV\n",
    "entregable.to_csv('C:\\\\Users\\\\acer\\\\Pictures\\\\7mo CICLO\\\\INTERNET DE LAS COSAS\\\\TAREA2\\\\DATA_TEMPERATURA_y_HUMEDAD_G1_iot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3a03e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
